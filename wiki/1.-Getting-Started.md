# Getting Started

This guide walks you through installing and launching RedAmon for the first time. By the end, you'll have the webapp running at `http://localhost:3000` and ready to create your first project.

---

## Prerequisites

You only need one thing installed on your machine:

- **[Docker](https://docs.docker.com/get-docker/) & Docker Compose v2+**

That's it. No Node.js, Python, or security tools needed on your host — everything runs inside containers.

### Minimum System Requirements

| Resource | Without OpenVAS | With OpenVAS (full stack) |
|----------|----------------|--------------------------|
| **CPU** | 2 cores | 4 cores |
| **RAM** | 4 GB | 8 GB (16 GB recommended) |
| **Disk** | 20 GB free | 50 GB free |

> **Without OpenVAS** runs 6 containers: webapp, postgres, neo4j, agent, kali-sandbox, recon-orchestrator.
>
> **With OpenVAS** adds 4 more runtime containers plus ~8 one-shot data-init containers for vulnerability feeds (~170K+ NVTs). First launch takes ~30 minutes for GVM feed synchronization.

---

## Step 1: Clone the Repository

```bash
git clone https://github.com/samugit83/redamon.git
cd redamon
```

---

## Step 2: Configure Environment Variables

Copy the example environment file:

```bash
cp .env.example .env
```

Open `.env` in your editor and add **at least one AI provider API key**:

```env
ANTHROPIC_API_KEY=sk-ant-...   # recommended
# or
OPENAI_API_KEY=sk-proj-...
```

Get your key from:
- **Anthropic**: [console.anthropic.com](https://console.anthropic.com/)
- **OpenAI**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

### Optional API Keys

These unlock additional capabilities:

```env
# Additional AI providers (see "AI Model Providers" wiki page for full setup)
OPENAI_COMPAT_BASE_URL=http://host.docker.internal:11434/v1  # Ollama, vLLM, LM Studio
OPENROUTER_API_KEY=sk-or-...   # 300+ models via openrouter.ai
AWS_ACCESS_KEY_ID=AKIA...      # AWS Bedrock foundation models
AWS_SECRET_ACCESS_KEY=...
AWS_DEFAULT_REGION=us-east-1

# Extra capabilities
TAVILY_API_KEY=tvly-...        # Web search for the AI agent (tavily.com)
NVD_API_KEY=...                # Faster CVE lookups (nist.gov/developers)
```

> For a complete guide on all AI providers, see [AI Model Providers](10.-AI-Model-Providers).

---

## Step 3: Build the Docker Images

```bash
docker compose --profile tools build
```

This builds all images including the recon pipeline, vulnerability scanner, and services. The build takes a few minutes on the first run.

---

## Step 4: Start the Services

**Full stack (with GVM/OpenVAS):**
```bash
docker compose up -d
```

**Lightweight (without GVM — faster startup):**
```bash
docker compose up -d postgres neo4j recon-orchestrator kali-sandbox agent webapp
```

The full stack includes the GVM/OpenVAS network vulnerability scanner. On first launch, GVM takes ~30 minutes to synchronize its feed of 170,000+ vulnerability tests. The lightweight option skips GVM entirely — you can always start it later.

> **Total image size:** ~15 GB

---

## Step 5: Open the Webapp

Navigate to **http://localhost:3000** in your browser.

<!-- Screenshot: 01-projects-page.png — The Projects page in its initial empty state, showing the "Create User" area on the left and the empty project grid on the right -->
![Projects Page](images/01-projects-page.png)

You should see the **Projects** page — the starting point for creating users and projects.

---

## What's Next?

Now that RedAmon is running:

1. **[Create a user](2.-User-Management)** — set up your identity
2. **[Create a project](3.-Creating-a-Project)** — configure your target and scan parameters
3. **[Explore the Graph Dashboard](4.-The-Graph-Dashboard)** — understand the main interface
4. **[Run your first reconnaissance](5.-Running-Reconnaissance)** — scan a target

---

## Common Commands

```bash
# Start all services (including GVM)
docker compose up -d

# Stop all services (keeps data)
docker compose down

# Check service status
docker compose ps

# Follow all logs
docker compose logs -f

# Follow specific service logs
docker compose logs -f webapp               # Next.js webapp
docker compose logs -f agent                # AI agent orchestrator
docker compose logs -f recon-orchestrator   # Recon orchestrator
docker compose logs -f kali-sandbox         # MCP tool servers
docker compose logs -f gvmd                 # GVM vulnerability scanner
docker compose logs -f neo4j                # Neo4j graph database
docker compose logs -f postgres             # PostgreSQL database

# Stop and remove locally built images (forces rebuild on next start)
docker compose --profile tools down --rmi local

# Full cleanup: remove all containers, images, and volumes (destroys all data!)
docker compose --profile tools down --rmi local --volumes --remove-orphans
```

### Development Mode

For active development with Next.js fast refresh (hot-reload on every file save):

```bash
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d
```

**Without GVM:**
```bash
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d postgres neo4j recon-orchestrator kali-sandbox agent webapp
```

**Refreshing Python services after code changes:**

Python services (`agent`, `recon-orchestrator`, `kali-sandbox`) have source code volume-mounted, but the running process needs a restart to pick up changes:

```bash
docker compose restart agent              # AI agent orchestrator
docker compose restart recon-orchestrator  # Recon orchestrator
docker compose restart kali-sandbox       # MCP tool servers
```

### Updating to a New Version

```bash
git pull origin master
docker compose --profile tools build
docker compose up -d
```
